
# Backend Architecture â€“ RiskReg Navigator

This document explains how the backend is structured, how to run it, and how it interacts with PostgreSQL + pgvector and DataCrunch.

---

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ app/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ main.py
    â”œâ”€â”€ core/
    â”‚   â””â”€â”€ config.py
    â”œâ”€â”€ db/
    â”‚   â”œâ”€â”€ session.py
    â”‚   â”œâ”€â”€ models/
    â”‚   â””â”€â”€ schemas/
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ router_documents.py
    â”‚   â”œâ”€â”€ router_chunks.py
    â”‚   â”œâ”€â”€ router_chat.py
    â”‚   â””â”€â”€ router_analytics.py
    â”œâ”€â”€ ingestion/
    â”‚   â”œâ”€â”€ xml_scanner.py
    â”‚   â”œâ”€â”€ xml_parser.py
    â”‚   â””â”€â”€ chunker.py
    â””â”€â”€ nlp/
        â”œâ”€â”€ embeddings.py
        â”œâ”€â”€ risk_classifier.py
        â””â”€â”€ contradictions.py
```

---

## ğŸš€ Setup Instructions

### 1. Install Docker & Docker Compose
Make sure Docker is installed on the DataCrunch server.

### 2. Project Clone
```
git clone <your_repo>
cd backend
```

### 3. Create `.env` file inside `backend/`
```
DATABASE_URL=postgresql+psycopg2://postgres:postgres@postgres:5432/riskreg
OPENAI_API_KEY=YOUR_KEY_HERE
```

---

## ğŸ³ Running the backend

### 1. Build and start all services
```
docker-compose up --build -d
```

### 2. Access FastAPI documentation
```
http://<YOUR-DATACRUNCH-IP>:8000/docs
```

### 3. Restart services
```
docker-compose restart
```

### 4. Stop
```
docker-compose down
```

---

## ğŸ—„ Database Structure

The backend uses:

- **PostgreSQL**
- **pgvector extension** for embeddings
- SQLAlchemy models:
  - `Document`
  - `Chunk`
  - (future) `RequirementPair`

Connections run through `backend/app/db/session.py`.

---

## ğŸ“‚ Dataset Location

Place the dataset under:

```
/home/<user>/project/data/
```

This folder is mounted into the FastAPI container automatically in `docker-compose.yml`.

Recommended structure:

```
data/
    gold/
        eu_leg/
        financial_regulation/
        national_laws/
    silver/
    bronze/
```

---

## ğŸ”Œ API Overview

The backend exposes:

- `/documents/*` â†’ document listing & metadata  
- `/chunks/*` â†’ chunk query + semantic search  
- `/chat/*` â†’ chatbot interface  
- `/analytics/*` â†’ dashboards & regulatory metrics  

Routers are located in `backend/app/api/`.

---

## ğŸ§  NLP Layer

Located in `backend/app/nlp/`.

Includes:

- `embeddings.py` â†’ vector generation  
- `risk_classifier.py` â†’ multilabel risk classification via LLM  
- `contradictions.py` â†’ NLI-based contradiction detection  

These functions are used after chunking to enrich each document.

---

## âš™ï¸ Ingestion Pipeline

Located in `backend/app/ingestion/`.

Steps:
1. `xml_scanner.py` â†’ detect all XML files  
2. `xml_parser.py` â†’ extract metadata & text  
3. `chunker.py` â†’ split text into semantic units (chunks)

---

## ğŸ¤ Contributions

Each backend component is modular:
- ingestion
- database
- NLP
- API routing

This allows multiple team members to work in parallel.

---

## ğŸ›  Troubleshooting

### Check logs:
```
docker logs riskreg-backend
docker logs riskreg-postgres
```

### Rebuild everything:
```
docker-compose down -v
docker-compose up --build
```

---